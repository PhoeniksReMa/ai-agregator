services:
  ollama:
    image: ollama/ollama:latest
    restart: unless-stopped
    environment:
      - OLLAMA_KEEP_ALIVE=24h
      - OLLAMA_MODELS=/root/.ollama
    volumes:
      - ${OLLAMA_MODELS}:/root/.ollama
      - ./ollama/entrypoint.sh:/entrypoint.sh
    entrypoint: [ "/bin/bash", "/entrypoint.sh" ]
    ports:
      - "11434:11434"
    runtime: nvidia

  xtts:
    build: ./xtts
    restart: unless-stopped
    environment:
      - COQUI_TTS_CACHE=${XTTS_CACHE}
      - HF_HUB_ENABLE_HF_TRANSFER=0
      - HF_HUB_DISABLE_TELEMETRY=1
      - NVIDIA_VISIBLE_DEVICES=${GPU_TTS}       # <<< добавь
    volumes:
      - ${XTTS_CACHE}:/root/.local/share/tts
    ports: ["8021:8021"]
    runtime: nvidia

  whisper:
    build: ./whisper
    restart: unless-stopped
    environment:
      - WHISPER_CACHE=${WHISPER_CACHE}
      - HF_HUB_ENABLE_HF_TRANSFER=0
      - HF_HUB_DISABLE_TELEMETRY=1
      - NVIDIA_VISIBLE_DEVICES=${GPU_WHISPER}   # <<< добавь
    volumes:
      - ${WHISPER_CACHE}:/root/.cache
    ports: ["8022:8022"]
    runtime: nvidia

  comfyui:
    build: ./comfyui
    restart: unless-stopped
    environment:
      - CLI_ARGS=--listen 0.0.0.0 --port 8188
      - NVIDIA_VISIBLE_DEVICES=${GPU_SD}        # <<< добавь (можно список через запятую)
    ports: ["8188:8188"]
    volumes:
      - ${COMFY_MODELS}:/opt/ComfyUI/models
    runtime: nvidia

  gateway:
    build: ./gateway
    restart: unless-stopped
    environment:
      - OLLAMA_URL=http://ollama:11434
      - XTTS_URL=http://xtts:8021
      - WHISPER_URL=http://whisper:8022
      - COMFY_URL=http://comfyui:8188
    ports: ["8080:8080"]
    depends_on: [ollama, xtts, whisper, comfyui]
